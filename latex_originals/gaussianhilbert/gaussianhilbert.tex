\documentclass{article}
\usepackage{amsmath,amssymb,mathrsfs,amsthm}
%\usepackage{tikz-cd}
\usepackage{hyperref}
\newcommand{\inner}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\tr}{\ensuremath\mathrm{tr}\,} 
\newcommand{\Span}{\ensuremath\mathrm{span}} 
\def\Re{\ensuremath{\mathrm{Re}}\,}
\def\Im{\ensuremath{\mathrm{Im}}\,}
\newcommand{\id}{\ensuremath\mathrm{id}} 
\newcommand{\var}{\ensuremath\mathrm{var}} 
\newcommand{\Lip}{\ensuremath\mathrm{Lip}} 
\newcommand{\GL}{\ensuremath\mathrm{GL}} 
\newcommand{\diam}{\ensuremath\mathrm{diam}} 
\newcommand{\sgn}{\ensuremath\mathrm{sgn}\,} 
\newcommand{\lcm}{\ensuremath\mathrm{lcm}} 
\newcommand{\supp}{\ensuremath\mathrm{supp}\,}
\newcommand{\dom}{\ensuremath\mathrm{dom}\,}
\newcommand{\upto}{\nearrow}
\newcommand{\downto}{\searrow}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\begin{document}
\title{Gaussian Hilbert spaces}
\author{Jordan Bell\\ \texttt{jordan.bell@gmail.com}\\Department of Mathematics, University of Toronto}
\date{\today}

\maketitle


\section{Gaussian measures}
Let $\gamma$ be a Borel probability measure on $\mathbb{R}$. For $a \in \mathbb{R}$, if 
$\gamma=\delta_a$ then we call $\gamma$ a \textbf{Gaussian measure with mean $a$ and variance $0$}.
If $\sigma>0$ and $\gamma$ has density
\[
p(t,a,\sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp\left(-\frac{(t-a)^2}{2\sigma^2}\right),\qquad t \in \mathbb{R},
\]
with respect to Lebesgue measure $\lambda_1$ on $\mathbb{R}$, then we call $\gamma$ a \textbf{Gaussian measure with 
mean $a$ and variance $\sigma^2$}.

A Borel probability measure $\gamma$ on $\mathbb{R}^n$ is called \textbf{Gaussian} if for each
$\xi \in (\mathbb{R}^n)^*$, the pushforward measure $\xi_* \gamma$ is a Gaussian measure on $\mathbb{R}$. 
The characteristic function of a Borel probability measure $\mu$ on $\mathbb{R}^n$ is
\[
\widetilde{\mu}(y) = \int_{\mathbb{R}^n} e^{i\inner{y}{x}} d\mu(x),\qquad y \in \mathbb{R}^n.
\]
We call a linear operator $C \in \mathscr{L}(\mathbb{R}^n)$ \textbf{positive} when $\inner{Cx}{x} \geq 0$ for all $x \in \mathbb{R}^n$.\footnote{We remark that
$\mathbb{R}^n$
is a real Hilbert space, and differently than a complex Hilbert space it need not be true that a positive linear operator
is self-adjoint.} It can be proved\footnote{\url{http://individual.utoronto.ca/jordanbell/notes/gaussian.pdf},
Theorem 5.} that a Borel probability measure $\gamma$ on $\mathbb{R}^n$ is Gaussian if and only
if there is some $a \in \mathbb{R}^n$ and some positive self-adjoint $C \in \mathscr{L}(\mathbb{R}^n)$ such that
\[
\widetilde{\gamma}(y) = \exp\left(i\inner{y}{a} - \frac{1}{2}\inner{Cy}{y} \right),\qquad y \in \mathbb{R}^n.
\]
We say that $\gamma$ has \textbf{mean} $a$ and \textbf{covariance operator}
$C$.
If $C$ is invertible (which is equivalent to $\inner{Cx}{x}>0$ for all nonzero $x \in \mathbb{R}^n$), then 
the density of $\gamma$ with respect to Lebesgue measure $\lambda_n$ on $\mathbb{R}^n$ is
\[
x \mapsto \frac{1}{\sqrt{(2\pi)^n \det C}} \exp\left(-\frac{1}{2}\inner{C^{-1}(x-a)}{x-a}\right), \qquad \mathbb{R}^n \to \mathbb{R}.
\]
The \textbf{standard Gaussian measure on $\mathbb{R}^n$}, denoted
$\gamma_n$,
is the Gaussian measure on $\mathbb{R}^n$ with mean $0$ and covariance operator $I$:
\[
d\gamma_n(x) =(2\pi)^{-n/2} \exp\left(-\frac{1}{2}\inner{x}{x}\right)d\lambda_n(x),
\]
where $\lambda_n$ is Lebesgue measure on $\mathbb{R}^n$. 
Throughout  the remainder of this note, when we speak of Gaussian measures we assume unless we say otherwise
that they have mean $0$.


\section{$\mathbb{R}^I$}
Let $I$ be the positive integers. 
For nonempty subsets $J$ and $K$ of $I$ with $J \subset K$, let $\pi_{K,J}:\mathbb{R}^K \to \mathbb{R}^J$ be the projection
map, and for $i \in I$ let $\pi_i = \pi_{I,\{i\}}$. 
For a topological space $X$, let $\mathscr{B}_X$ be the Borel $\sigma$-algebra of $X$.

If $B_i \in \mathscr{B}_{\mathbb{R}}$ for each $i \in I$ and $\{i \in I: B_i \neq \mathbb{R}\}$ is finite,
we call
\[
\prod_{i \in I} B_i \subset \mathbb{R}^I
\]
a \textbf{cylinder set}. 
The $\sigma$-algebra generated by the collection of all cylinder sets is called the \textbf{product
$\sigma$-algebra}, and is denoted by
$\mathscr{B}_{\mathbb{R}}^I$.
The product measure $\gamma_I = \prod_{i \in I} \gamma_1$ is the unique probability measure\footnote{\url{http://individual.utoronto.ca/jordanbell/notes/productmeasure.pdf}} on the product $\sigma$-algebra $\mathscr{B}_{\mathbb{R}}^I$ such that
for each cylinder set $\prod_{i \in I} B_i$,
\[
\gamma_I \left( \prod_{i \in I} B_i \right) = \prod_{i \in I} \gamma_1(B_i).
\]
Because $I$ is countable and $\mathbb{R}$ is a second-countable topological space, the Borel $\sigma$-algebra of
$\mathbb{R}^I$, with the product topology, is equal to the product $\sigma$-algebra on $\mathbb{R}^I$:\footnote{\url{http://individual.utoronto.ca/jordanbell/notes/kolmogorov.pdf},
Theorem 7.}
\[
\mathscr{B}_{\mathbb{R}^I} = \mathscr{B}_{\mathbb{R}}^I.
\]
Thus $\gamma_I$ is a Borel probability measure on $\mathbb{R}^I$. 


On the one hand, $\mathbb{R}^I$ is a real vector space. On the other hand, with the product topology it is a topological space.
It can be proved that
with the separating family of seminorms $\{|\pi_i|: i \in I\}$ it is a Fr\'echet space,\footnote{Charalambos D. Aliprantis
and Kim C. Border, {\em Infinite Dimensional Analysis: A Hitchhiker's Guide}, third ed., p.~207, Example 5.78.} whose topology (the product topology) is induced by the complete
translation invariant metric
\[
d(x,y) = \sum_{i \in I} 2^{-i} \frac{|x_i-y_i|}{1+|x_i-y_i|},
\qquad x,y \in \mathbb{R}^I.
\]
We remark that because $\mathbb{R}^I$ is a countable product of second-countable topological spaces, it is itself
a second-countable topological space, and so is separable. The \textbf{dual space of $\mathbb{R}^I$}, denoted $(\mathbb{R}^I)^*$, is the collection
of continuous linear maps $\mathbb{R}^I \to \mathbb{R}$. It turns out that the dual space $(\mathbb{R}^I)^*$ of $\mathbb{R}^I$ is equal to the
collection of those $x \in \mathbb{R}^I$ such that $\{i \in I: \pi_i(x) \neq 0\}$ is finite,\footnote{Charalambos D. Aliprantis
and Kim C. Border, {\em Infinite Dimensional Analysis: A Hitchhiker's Guide}, third ed., p.~528, Theorem 16.3.} 
with the dual pair
\[
\inner{x}{y} = \sum_{i \in I} x_i y_i,\qquad x \in \mathbb{R}^I,\quad y \in (\mathbb{R}^I)^*.
\]



\section{Gaussian Hilbert spaces}
Because $\mathbb{R}^I$ is 
a second-countable topological space, its Borel $\sigma$-algebra $\mathscr{B}_{\mathbb{R}^I}$ is countably
generated, and because $\gamma_I$ is a probability measure on $\mathscr{B}_{\mathbb{R}^I}$ it is a fortiori
$\sigma$-finite, so
the real Hilbert space $L^2(\gamma_I)$ is separable.\footnote{Donald L. Cohn,
{\em Measure Theory}, second ed., p.~102, Proposition 3.4.5.}


Let $\mathscr{H}$ be a real separable Hilbert space, with inner product $\inner{\cdot}{\cdot}$ and norm
$\norm{\cdot}$,  let $e_i$, $i \in I$, be an orthonormal basis for $\mathscr{H}$, and let $V$
be the linear span of this basis. In particular, $V$ is a dense linear subspace of $\mathscr{H}$.
For $v \in V$, define
\[
\phi(v) = \sum_{i \in I} \inner{v}{e_i} \pi_i.
\]
Using
\[
\int_{\mathbb{R}} x_i d\gamma_1(x_i) =0,\qquad
\int_{\mathbb{R}} x_i^2 d\gamma_1(x_i) = 1,
\]
we calculate\footnote{\url{http://individual.utoronto.ca/jordanbell/notes/parseval.pdf}}
\begin{align*}
\norm{\phi(v)}_{L^2(\gamma_I)}^2&=\int_{\mathbb{R}^I} |\phi(v)(x)|^2 d\gamma_I(x)\\
&= \sum_{i \in I} \int_{\mathbb{R}^I} 
\inner{v}{e_i}^2 \pi_i(x)^2d\gamma_I(x)\\
&+\sum_{i \in I} \int_{\mathbb{R}^I} \inner{v}{e_i} \inner{v}{e_j} \pi_i(x) \pi_j(x)d\gamma_I(x)\\
&=\sum_{i \in I} \inner{v}{e_i}^2\\
&=\norm{v}^2,
\end{align*}
showing that $\phi:V \to L^2(\gamma_I)$ is a linear isometry. 
Because (i) $V$ is a dense linear subspace of $\mathscr{H}$, (ii) the operator  $\phi:V \to L^2(\gamma_I)$ is bounded,
and (iii) $L^2(\gamma_I)$ is a Hilbert space, 
there is a unique bounded linear operator
$\Phi:\mathscr{H} \to L^2(\gamma_I)$ whose restriction to $V$ is equal to $\phi$.\footnote{Walter
Rudin, {\em Functional Analysis}, second ed., p.~39, Exercise 19.}
For $v \in \mathscr{H}$ there is a sequence $v_n$ in $V$ that tends to $v$, and because $\Phi$ is continuous
and $\norm{\cdot}:\mathscr{H} \to \mathbb{R}$
is continuous,
\[
\norm{\Phi (v)} = \lim_{n \to \infty} \norm{\Phi(v_n)}
=\lim_{n \to \infty} \norm{\phi(v_n)}
=\lim_{n \to \infty} \norm{v_n}
=\norm{v},
\]
showing that $\Phi$ is  a linear isometry. 

Define $F:\mathscr{H} \to \mathbb{C}$ by
\[
F(v) = \int_{\mathbb{R}^I} \exp(i\Phi(v)(x)) d\gamma_I(x).
\]
Because $|e^{is}-e^{it}| \leq |s-t|$, and using the Cauchy-Schwarz
inequality, for $v,w \in \mathscr{H}$,
\begin{align*}
|F(v)-F(w)|&\leq \int_{\mathbb{R}^I} \left|  \exp(i\Phi(v)(x))  - \exp(i\Phi(w)(x)) \right| d\gamma_I(x)\\
&\leq \int_{\mathbb{R}^I} |\Phi(v)(x)-\Phi(w)(x)| d\gamma_I(x)\\
&=\int_{\mathbb{R}^I} |\Phi(v-w)(x)| d\gamma_I(x)\\
&\leq \norm{\Phi(v-w)}_{L^2(\gamma_I)}\\
&=\norm{v-w},
\end{align*}
which shows in particular that $F$ is continuous.
For $v \in V$, let $I_v=\{i \in I: \inner{v}{e_i}\} \neq 0$, which is finite.
We calculate using Fubini's theorem
\begin{align*}
F(v)&=
\int_{\mathbb{R}^I} \exp\left(i\sum_{i \in I} \inner{v}{e_i} \pi_i(x) \right) d\gamma_I(x)\\
&=\int_{\mathbb{R}^I} \prod_{i \in I} \exp(i\inner{v}{e_i} \pi_i(x)) d\gamma_I(x)\\
&=\prod_{i \in I_v} \int_{\mathbb{R}}   \exp(i\inner{v}{e_i} t) d\gamma_1(t)\\
&=\prod_{i \in I_v} \widetilde{\gamma}_1(\inner{v}{e_i})\\
&=\prod_{i \in I_v} \exp\left(-\frac{1}{2} |\inner{v}{e_i}|^2\right)\\
&=\exp\left(-\frac{1}{2} \norm{v}^2\right).
\end{align*}
For $v \in \mathscr{H}$, there is a sequence $v_n \in V$ that tends to $v$, and because $F$ and 
$w \mapsto \exp\left(-\frac{1}{2} \norm{w}^2\right)$ are
 continuous, 
\[
F(v) = \lim_{n \to \infty} F(v_n) = \lim_{n \to \infty} \exp\left(-\frac{1}{2} \norm{v_n}^2\right)
=\exp\left(-\frac{1}{2} \norm{v}^2 \right).
\]
That is, for all $v \in \mathscr{H}$,
\[
 \int_{\mathbb{R}^I} \exp(i\Phi(v)(x)) d\gamma_I(x) = \exp\left(-\frac{1}{2} \norm{v}^2 \right).
\]

For distinct $v_1,\ldots,v_n \in \mathscr{H}$, write $X=\Phi(v_1) \otimes \cdots \otimes \Phi(v_n)$, which is measurable
$\mathbb{R}^I \to \mathbb{R}^n$, and let $\mu$ be the pushforward measure of $\gamma_I$ by $X$, namely the joint distribution
of the random variables $\Phi(v_1),\ldots,\Phi(v_n)$. 
For $y \in \mathbb{R}^n$ we calculate
using the change of variables theorem\footnote{Charalambos D. Aliprantis
and Kim C. Border, {\em Infinite Dimensional Analysis: A Hitchhiker's Guide}, third ed., p.~484, Theorem 13.46.}
and Fubini's theorem
\begin{align*}
\widetilde{\mu}(y)&=\int_{\mathbb{R}^n} e^{i\inner{y}{u}} d\mu(u)\\
&=\int_{\mathbb{R}^I} e^{i\inner{y}{X(x)}} d\gamma_I(x)\\
&=\int_{\mathbb{R}^I} e^{i(y_1\Phi(v_1)(x)+\cdots+y_n\Phi(v_n)(x))} d\gamma_I(x)\\
&=\int_{\mathbb{R}^I} e^{i\Phi(y_1v_1+\cdots+y_nv_n)(x)} d\gamma_I(x)\\
&= \exp\left(-\frac{1}{2} \norm{y_1v_1+\cdots+y_nv_n}^2 \right)\\
&=\exp\left(-\frac{1}{2} \sum_{i,j}  \inner{v_i}{v_j} y_i y_j \right),
\end{align*}
which shows that $\mu$ is a Gaussian measure on $\mathbb{R}^n$ with covariance matrix 
$C_{i,j}=\inner{v_i}{v_j}$.\footnote{See Barry Simon, {\em Functional Integration and Quantum Physics}, p.~16, Theorem 2.3A.}
Thus $\{\Phi(v)\}_{v \in \mathscr{H}}$ is a stochastic process with sample space $(\mathbb{R}^I,\mathscr{B}_{\mathbb{R}^I},\gamma_I)$,
index set $\mathscr{H}$, and
state space $\mathbb{R}$, which we call the \textbf{Gaussian process with covariance $\inner{\cdot}{\cdot}$}.


Let $T$ be a separable metric space
and suppose that $c:T \times T \to \mathbb{R}$ is continuous
and that for any  $t_1,\ldots,t_n \in T$, 
$\{c(t_i,t_j)\}_{1 \leq i,j \leq n}$ is a symmetric positive semidefinite matrix. 
For each $t \in T$ let $\delta_t$ be a formal symbol, and let
$V$ be the linear span of $\{\delta_t: t \in T\}$. 
For $v,w \in V$, there are 
distinct $t_1,\ldots,t_n \in T$ and real numbers $\alpha_1,\ldots,\alpha_n,\beta_1,\ldots,\beta_n$
such that 
$v=\sum_{i=1}^n \alpha_i \delta_{t_i}$ and $w=\sum_{i=1}^n \beta_i \delta_{t_i}$, 
 and we define
\[
[v,w] = \sum_{1 \leq i,j \leq n} \alpha_i \beta_j c(t_i,t_j).
\]
For $a \in \mathbb{R}$,
\[
[a v,w] =  \sum_{1 \leq i,j \leq n} (a \alpha_i) \beta_j c(t_i,t_j)
=a  \sum_{1 \leq i,j \leq n} \alpha_i \beta_j c(t_i,t_j)
=a[v,w].
\]
For $u,v,w \in V$ there are 
distinct $t_1,\ldots,t_n \in T$ and real numbers
\[
\alpha_1,\ldots,\alpha_n,\qquad \beta_1,\ldots,\beta_n, \qquad
\gamma_1,\ldots,\gamma_n
\]
 such that
$v=\sum_{i=1}^n \alpha_i \delta_{t_i}$, $w=\sum_{i=1}^n \beta_i \delta_{t_i}$, 
$u=\sum_{i=1}^n \gamma_i \delta_{t_i}$, and
\[
[u+v,w] = \sum_{1 \leq i,j \leq n} (\alpha_i+\gamma_i)\beta_j c(t_i,t_j)
=[u,w]+[v,w].
\]
Because $\{c(t_i,t_j)\}_{1 \leq i,j \leq n}$ is symmetric, $[v,w]=[w,v]$. 
Finally, because the matrix $\{c(t_i,t_j)\}_{1 \leq i,j \leq n}$ is positive semidefinite,
\[
[v,v]=\sum_{1 \leq i,j \leq n} \alpha_i \alpha_j c(t_i,t_j)
\geq 0.
\]
This establishes that $[\cdot,\cdot]$ is a positive semidefinite inner product on $V$. 
Then $|v| = \sqrt{[v,v]}$,
\[
|v|^2 =  \sum_{1 \leq i,j \leq n} \alpha_i \alpha_j c(t_i,t_j),
\]
is a seminorm on $V$, and $N=\{v \in V: |v|=0\}$ is a closed linear subspace of $V$. Let
\[
V/N = \{v+N: v \in V\},
\] 
For $v,w \in V$ and $r,s \in N$, because $|r|=0$ and $|s|=0$, by the Cauchy-Schwarz inequality (which
is indeed true for a positive semidefinite inner product)\footnote{A. Ya. Helemskii,
{\em Lectures and Exercises on Functional Analysis}, p.~68, Theorem 1.}
we have
$|[v,s]|^2 \leq |v||s| = 0$ and $|[r,w]|^2 \leq |r||w|=0$, hence 
\[
[v+r,w+s] = [v,w]+[v,s]+[r,w]+[r,s] = [v,w].
\]
Therefore it makes sense to define 
\[
\inner{v+N}{w+N} = [v,w].
\]
If $\inner{v+N}{w+N}=0$ then $[v,v]=0$, i.e. $|v|=0$ and so $v \in N$, i.e. $v+N=0 \in V/N$, and therefore
$\inner{\cdot}{\cdot}$ is an inner product on $V/N$. 
Then there is a Hilbert space $(\mathscr{H},\inner{\cdot}{\cdot})$ and a
linear isometry $i:V/N \to \mathscr{H}$ whose image is a dense subset of $\mathscr{H}$, called a \textbf{completion} of $V/H$,
and this completion is unique up to a unique isomorphism of Hilbert spaces.\footnote{A. Ya. Helemskii,
{\em Lectures and Exercises on Functional Analysis}, p.~172, Proposition 3.}


$T$ is separable so it has  a countable dense subset $S$.
 For $t \in T$,
 either $t \in S$ or $t \not \in S$. If $t \not \in S$, 
  there is a sequence of distinct $s_k$ in $S$ that tends to $t$, and 
  because $c$ is continuous,
\[
|\delta_{s_k}-\delta_t|^2 = c(s_k,s_k)-c(s_k,t)-c(t,s_k)+c(t,t) \to c(t,t)-c(t,t)-c(t,t)+c(t,t),
\]
so $\delta_{s_k} \to \delta_t$ in $V$, which shows that $\delta:T \to V$ is continuous.
Let $W$ be the $\mathbb{Q}$-linear span of $\{\delta_s: s \in S\}$. $W$ is countable, and it follows from the above that 
$W$ is dense in $V$. 
Define $\pi:V \to V/N$ by $\pi(v)=v+N$, which is an onto continuous linear map.
Then the image of $W$ under $i \circ \pi:V \to \mathscr{H}$ is dense in $\mathscr{H}$, thus
$(\mathscr{H},\inner{\cdot}{\cdot})$ is a separable Hilbert space.



Now let $\{\Phi(v)\}_{v \in \mathscr{H}}$ be the \textbf{Gaussian process with covariance $\inner{\cdot}{\cdot}$},
and define $q:T \to L^2(\gamma_I)$ by
\[
q = \Phi \circ i \circ \pi \circ \delta.
\]
For distinct $t_1,\ldots,t_n \in T$, the vectors $v_j=(i \circ \pi \circ \delta)(t_j) \in \mathscr{H}$, $1 \leq j \leq n$, are distinct.
Then $(\Phi(v_1) \otimes \cdots \otimes \Phi(v_n))_* \gamma_I$ is the Gaussian measure on $\mathbb{R}^n$
with covariance matrix
\[
C_{i,j}=\inner{v_i}{v_j}=\inner{(i \circ \pi \circ \delta)(t_i)}{(i \circ \pi \circ \delta)(t_j)}
=[\delta_{t_i},\delta_{t_j}]
=c(t_i,t_j).
\]
That is, the joint distribution of the random variables
$q_{t_1},\ldots,q_{t_n}$ is the Gaussian measure on $\mathbb{R}^n$ with covariance
matrix $C_{i,j}=c(t_i,t_j)$. 


\end{document}