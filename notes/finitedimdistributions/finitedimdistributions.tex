\documentclass{article}
\usepackage{amsmath,amssymb,mathrsfs,amsthm}
%\usepackage{tikz-cd}
\usepackage{hyperref}
\newcommand{\inner}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\tr}{\ensuremath\mathrm{tr}\,} 
\newcommand{\Span}{\ensuremath\mathrm{span}} 
\def\Re{\ensuremath{\mathrm{Re}}\,}
\def\Im{\ensuremath{\mathrm{Im}}\,}
\newcommand{\id}{\ensuremath\mathrm{id}} 
\newcommand{\diam}{\ensuremath\mathrm{diam}} 
\newcommand{\lcm}{\ensuremath\mathrm{lcm}} 
\newcommand{\supp}{\ensuremath\mathrm{supp}\,}
\newcommand{\dom}{\ensuremath\mathrm{dom}\,}
\newcommand{\upto}{\nearrow}
\newcommand{\downto}{\searrow}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\begin{document}
\title{Finite-dimensional distributions of stochastic processes}
\author{Jordan Bell\\ \texttt{jordan.bell@gmail.com}\\Department of Mathematics, University of Toronto}
\date{\today}

\maketitle

\section{Products of probability spaces}
Let $I$ be a nonempty set,  and for each
$i \in I$, let $(E_i,\mathscr{E}_i,\mu_i)$ be a probability space.
Let
\[
E=\prod_{i \in I} E_i,
\]
the collection of functions
$e:I \to \bigcup_{i \in I} E_i$ such that for each $i$, $e(i) \in E_i$.
Let
\[
\pi_i:E \to E_i
\]
 be the \textbf{projection map}: $\pi_i(e) = e(i)$. 
Let
\[
\mathscr{E} = \bigotimes_{i \in I} \mathscr{E}_i,
\]
 the \textbf{product $\sigma$-algebra}, which is
the coarsest $\sigma$-algebra on $E$ such that each $\pi_i$ is measurable
$\mathscr{E} \to \mathscr{E}_i$.\footnote{See \url{http://individual.utoronto.ca/jordanbell/notes/kolmogorov.pdf}}

Let $\mu=\prod_{i \in I} \mu_i$, the unique probability measure\footnote{See \url{http://individual.utoronto.ca/jordanbell/notes/productmeasure.pdf}} on $\mathscr{E}$ such that when $J$ is a   finite nonempty subset of $I$
and $A_i \in \mathscr{E}_i$ for each $i \in J$,
\[
\mu\left( \prod_{i \in J} A_i \times \prod_{i \in I \setminus J} E_i \right) = \prod_{i \in J} \mu_i(A_i).
\]


\section{Joint distributions}
Let $(\Omega,\mathscr{F},P)$ be a probability space, and for each $i \in I$ let
$X_i:(\Omega,\mathscr{F}) \to (E_i,\mathscr{E}_i)$ be measurable.
Let $P_{X_i}={X_i}_*P$, the \textbf{distribution} of $X_i$, which is a probability measure
on $\mathscr{E}_i$: for $A \in \mathscr{E}_i$,
\[
P_{X_i}(A) = ({X_i}_*P)(A) = P(X_i^{-1}(A)).
\]
In other words, $P_{X_i}$ is the pushforward of the probability measure $P$ by the random variable $X_i$.

A family of $\sigma$-algebras $(\mathscr{F}_i)_{i \in I}$, each contained
in $\mathscr{F}$, is said to be \textbf{independent} when
for any finite nonempty subset $J$ of $I$ and  for $A_i \in \mathscr{F}_i$ for $i \in J$,
\[
P\left( \bigcap_{i \in J} A_i \right) = \prod_{i \in J} P(A_i).
\]
The family of random variables $(X_i)_{i \in I}$ is called \textbf{independent} when
the family of $\sigma$-algebras $(\sigma(X_i))_{i \in I}$ is independent. 

Define
\[
X=\bigotimes_{i \in I} X_i:\Omega \to E
\]
by
$X(\omega)(i) = X_i(\omega)$,
i.e.  $\pi_i \circ X = X_i$.
$X$ is measurable $\mathscr{F} \to \mathscr{E}$ because for each $i$,
$\pi_i \circ X$ is measurable
$\mathscr{F} \to \mathscr{E}_i$.
The \textbf{joint distribution of the family $(X_i)_{i \in I}$} is
\[
P_X = X_*P,
\]
the pushforward of the measure $P$ by the random variable $X$. The joint distribution
$P_X$ is a probability measure on the product $\sigma$-algebra $\mathscr{E}$. 


If $J$ is a finite nonempty subset of $I$, $A_i \in \mathscr{E}_i$ for $i \in J$, and
$A = \prod_{i \in J} A_i \times \prod_{i \in I \setminus J} E_i$, 
on the one hand
\[
X^{-1}(A) = \bigcap_{i \in I} X_i^{-1}(\pi_i(A)) =\bigcap_{i \in J} X_i^{-1}(A_i)
\]
and thus
\[
P_X(A) = (X_*P)(A) = P(X^{-1}(A)) = P\left(\bigcap_{i \in J} X_i^{-1}(A_i) \right),
\]
and on the other hand
\[
\left(\prod_{i \in I} P_{X_i} \right)(A) = \prod_{i \in J} P_{X_i}(A_i).
\]


The following theorem states that the
joint distribution $P_X$ is equal to the product of the distributions $P_{X_i}$
if and only if the family
$(X_i)_{i \in I}$ is independent.\footnote{Heinz
Bauer, {\em Probability Theory}, p.~62, Theorem 9.4.}

\begin{theorem}
The family of random variables $(X_i)_{i \in I}$ is independent if and only if
\[
P_X = \prod_{i \in I} P_{X_i}.
\]
\end{theorem}



\section{Stochastic processes and projective families}
Let   $(E,\mathscr{E})$ be a measurable space let $I$ be a nonempty set. For a nonempty subset $J$ of $I$, 
let
\[
E^J = \prod_{t \in J} E
\]
and let
\[
\mathscr{E}^J = \bigotimes_{t \in J} \mathscr{E}.
\]
For nonempty subsets $J$ and $K$ of $I$ with $J \subset K$, let
\[
\pi_{K,J}:E^K \to E^J
\]
be the projection map: $\pi_{K,J}(f)(t)=f(t)$ for $t \in J$. 
$\pi_{K,J}$ is measurable  $\mathscr{E}^K \to \mathscr{E}^J$. 
We write
\[
\pi_J = \pi_{I,J}. 
\]

A \textbf{stochastic process} is a family $(X_t)_{t \in I}$
 of random variables
 $(\Omega,\mathscr{F},P) \to (E,\mathscr{E})$. 
 For a finite nonempty subset $J$ of $I$, define
 \[
 X_J = \bigotimes_{t \in J} X_t:\Omega \to E^J
 \]
by $X_J(\omega)(i)=X_i(\omega)$ for $i \in J$, i.e.
$\pi_i \circ X_J = X_i$ for $i \in J$.
$X_J$ is measurable $\mathscr{F} \to \mathscr{E}^J$. 
Let $P_J$ be the joint distribution of the family of
random variables $(X_t)_{t \in J}$, the probability measure on
$\mathscr{E}^J$ defined by, for $A \in \mathscr{E}^J$,
\[
P_J(A) = ({X_J}_*P)(A) = P(X_J^{-1}(A)).
\]
For finite nonempty subsets $J$ and $K$ of $I$ with $J \subset K$,
\[
X_J = \pi_{K,J} \circ X_K.
\]
Then for $A \in \mathscr{E}^J$,
\[
((\pi_{K,J})_*P_K)(A)=
P_K(\pi_{K,J}^{-1}(A))
=P(X_K^{-1}(\pi_{K,J}^{-1}(A)))
=P(X_J^{-1}(A))
=P_J(A),
\]
thus
\begin{equation}
(\pi_{K,J})_*P_K = P_J.
\label{projective}
\end{equation}

Let
\[
\mathscr{K}(I)
\]
 be the collection of all finite nonempty subsets of $I$. We call
$(E^J,\mathscr{E}^J,P_J)_{J \in \mathscr{K}(I)}$ the \textbf{family of finite-dimensional distributions}
of the stochastic process $(X_t)_{t \in I}$. 

On the other hand, if $I$ is a nonempty set, $(E,\mathscr{E})$ is a measurable space,
and for each $J \in \mathscr{K}(I)$, $P_J$ is a probability measure
on $\mathscr{E}^J$ such that
\eqref{projective} is true for all $J, K \in \mathscr{K}(I)$ with $J \subset K$, we
say that $(E^J,\mathscr{E}^J,P_J)_{J \in \mathscr{K}(I)}$ is a \textbf{projective family}.  
The following gives a weaker condition that in fact is sufficient  for  $(P_J)_{J \in \mathscr{K}(I)}$ to be a projective family.\footnote{Heinz Bauer,
{\em Probability Theory}, p.~300, Remark 1.}

\begin{lemma}
If \eqref{projective} is true for all $J, K \in \mathscr{K}(I)$ with $J \subset K$ and
$K \setminus J$ a singleton, then $(P_J)_{J \in \mathscr{K}(I)}$ is a projective family.
\end{lemma}
\begin{proof}
If $J,K \in \mathscr{K}(I)$, $J \subset K$, and $K \setminus J$ consists of $n$ distinct elements, write
\[
K_0 = J \subset K_1  \subset \cdots \subset K_n = K,
\]
where $K_j \setminus K_{j-1}$ is a singleton for each $j$. By  hypothesis,
$(\pi_{K_j, K_{j-1}})_* P_{K_j} = P_{K_{j-1}}$ for each $j$.
Because
\[
\pi_{K_n,K_0} = \pi_{K_n,K_{n-1}} \circ \cdots \circ \pi_{K_1,K_0},
\]
it follows that
\[
(\pi_{K_n,K_0})_*(K_n) = K_0.
\]
\end{proof}


The following is the \textbf{Kolmogorov extension theorem}.\footnote{\url{http://individual.utoronto.ca/jordanbell/notes/kolmogorov.pdf};
Heinz Bauer, {\em Probability Theory}, p.~301, Theorem 35.3.}

\begin{theorem}[Kolmogorov extension theorem]
If $E$ is a Polish space, $\mathscr{E}$ is the Borel $\sigma$-algebra of $E$, $I$ is a nonempty set, and
$(E^J,\mathscr{E}^J,P_J)_{J \in \mathscr{K}(I)}$ is a projective family,
then there is a unique probability measure
$P_I$ on $\mathscr{E}^I$ such that for any $J \in \mathscr{K}(I)$,
\[
{\pi_J}_*P_I = P_J.
\]
\end{theorem}

$P_I$ is called the \textbf{projective limit} of the projective family.



Suppose that $E$ is a Polish space with Borel $\sigma$-algebra $\mathscr{E}$, that
$I$ is a nonempty set,
and that $(E^J,\mathscr{E}^J,P_J)_{J \in \mathscr{K}(I)}$ is a projective family,
and let
\[
\Omega = E^I,\qquad \mathscr{F}= \mathscr{E}^I,\qquad P = P_I.
\]
$(\Omega,\mathscr{F},P)$ is a probability space.
For $t \in I$, define $X_t:\Omega \to E$ by
\[
X_t(\omega) = \pi_t(\omega) = \omega(t),
\]
which is measurable $\mathscr{F} \to \mathscr{E}$.
The family $(X_t)_{t \in I}$ is a stochastic process. For $J \in \mathscr{K}(I)$,
\[
X_J = \pi_J,
\]
 and thus for $A \in \mathscr{E}^J$, using that $P=P_I$ is the projective limit of $P_J$,
\[
({X_J}_*P)(A)= P_I(\pi_J^{-1}(A)) = ({\pi_J}_* P_I)(A) = P_J(A),
\]
which shows that $P_J$ is the joint distribution of the family $(X_t)_{t \in J}$. 
Thus, $(X_t)_{t \in I}$ is a stochastic process whose family of finite-dimensional distributions is
$(P_J)_{J \in \mathscr{K}(I)}$. 





\end{document}